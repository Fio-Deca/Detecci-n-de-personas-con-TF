# -*- coding: utf-8 -*-
"""Copy of [Clase] entrenamiento-modelos.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17lDLORURptAG6yV2nkJcP0DiXXytpiTX
"""

#Importamos las librerías necesarias 
import os
import pandas as pd
import json
import pickle
import zipfile
import shutil


# Instalamos los paquetes necesarios para que funcione desde Google Colab
!pip uninstall tensorflow 
!pip install tensorflow==2.7
!pip install avro-python3
!pip install 
!pip install tf_slim==1.1.0
!pip install tf-models-official==2.7.0
!pip install lvis
!pip install tensorflow_io==0.23.1
!pip install keras==2.6.0
!pip install opencv-python-headless==4.5.2.52
!pip install tensorflow-io
import tensorflow_io as tfio

#Creamos un archivo Label Map que contendrá los items
labels = [{'name':'Personas', 'id': 1}]
with open("label_map.pbtxt", "w") as f:
  for label in labels:
    f.write('item { \n')
    f.write('\tname:\'{}\'\n'.format(label['name']))
    f.write('\tid:{}\n'.format(label['id']))
    f.write('}\n')

# Commented out IPython magic to ensure Python compatibility.
#Instalamos Object detection
import os
# %cd /content
!git clone --quiet https://github.com/tensorflow/models.git
# %cd /content/models/
#!git checkout 58d19c67e1d30d905dd5c6e5092348658fed80af
!apt-get update && apt-get install -y -qq protobuf-compiler python-pil python-lxml python-tk
!pip install -q Cython contextlib2 pillow lxml matplotlib
!pip install -q pycocotools
# %cd /content/models/research
!protoc object_detection/protos/*.proto --python_out=.
os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'
!python object_detection/builders/model_builder_test.py

# Descargamos los modelos pre-entrenados en este caso será el SSD + MobileNetV2
!wget --no-check-certificate http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz \
    -O /content/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz

#Descomprimimos el modelo pre-entrenado
!tar -zxvf /content/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz
output_path = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'
output_path = os.path.join(os.getcwd(), output_path)
print("La carpeta se almaceno en {}".format(output_path))

#Definimos la ruta de nuestro modelo
path_training = '/content/ssd_mobilenet'
os.mkdir(path_training)

"""Definimos la ruta del archivo original pipeline.config y en dónde vamos 
a almacenar nuestro pipeline.config """
source_config = "{}/pipeline.config".format(output_path)
target_config = "{}/pipeline.config".format(path_training)
shutil.copyfile(source_config, target_config)

#Importamos las librerías para poder configurar el archivo pipeline.config
import tensorflow as tf
from object_detection.utils import config_util
from object_detection.protos import pipeline_pb2
from google.protobuf import text_format

# Obtenemos la configuración del archivo pipeline
config = config_util.get_configs_from_pipeline_file(target_config)

# Visualizamos la configuración base
config

# Creamos una variable proto_str para poder modificar las variables del archivo pbtxt
pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()
with tf.io.gfile.GFile(target_config, "r") as f:
  proto_str = f.read()
  text_format.Merge(proto_str, pipeline_config)

pipeline_config

# Definimos las rutas en donde se encuentra los TFRecords y el label map para agregarlos al archivo de configuración del pipeline.config
label_map_pbtxt_fname = "/content/label_map.pbtxt"
train_record_fname = "/content/train.record"
test_record_fname = "/content/test.record"

# Cantidad de clases del modelo
pipeline_config.model.ssd.num_classes = 2

# El tamaño del batch size, entre más grande más costo computacional va a necesitar en el proceso de entrenamiento, pero a su vez entrenará más rápido.
pipeline_config.train_config.batch_size = 4

# Donde almacenaremos los resultados del entrenamiento
pipeline_config.train_config.fine_tune_checkpoint ="{}/checkpoint/ckpt-0".format(output_path)

# Qué tipo de detección aplicaremos (Object detection)
pipeline_config.train_config.fine_tune_checkpoint_type = "detection"

# Dirección del label map
pipeline_config.train_input_reader.label_map_path = label_map_pbtxt_fname

# Dirección del train TFRecord
pipeline_config.train_input_reader.tf_record_input_reader.input_path[0] = train_record_fname

# Dirección del label map
pipeline_config.eval_input_reader[0].label_map_path = label_map_pbtxt_fname

# Dirección del test TFRecord
pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[0] = test_record_fname

# Visualizamos nuestro pipeline_config final.
pipeline_config

# Almacenamos nuestro archivo final
config_text = text_format.MessageToString(pipeline_config)
with tf.io.gfile.GFile(target_config, "wb") as f:
  f.write(config_text)

#Entrenamiento de modelo de object detection
num_steps = 5000
model_dir = "/content/ssd_mobilenet"

# Utilizamos directamente la librería de object detection para ejecutar el script model_main_tf2
# Los argumentos principales son el archivo de configuración, la ubicación del modelo y la cantidad de steps que ejecutará.
!python /content/models/research/object_detection/model_main_tf2.py \
--pipeline_config_path={target_config} \
--model_dir={model_dir} \
--num_train_steps={num_steps}

# Commented out IPython magic to ensure Python compatibility.
#Analizamos los resultados con tesorboard
# %load_ext tensorboard
# %tensorboard --logdir "/content/ssd_mobilenet"

#Exportación de modelo
output_directory = "/content/fine_tuned_model"

!python /content/models/research/object_detection/exporter_main_v2.py \
--input_type image_tensor \
--pipeline_config_path {target_config} \
--trained_checkpoint_dir {model_dir} \
--output_directory {output_directory}

#Comprimimos el modelo
!zip -r /content/fine_tuned_model.zip /content/fine_tuned_model